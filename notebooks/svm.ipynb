{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27609b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling libraries\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stanza\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import json_normalize\n",
    "\n",
    "# Natural Language Processing (NLP) libraries\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Scikit-learn modeling libraries\n",
    "\n",
    "from sklearn.svm import LinearSVC, SDGClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a78989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '../data/Kaggle2025/train.jsonl'\n",
    "df = pd.read_json(path, lines=True)\n",
    "df = json_normalize(df.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 23:29:55 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 435kB [00:00, 6.35MB/s]                    \n",
      "2025-11-17 23:29:55 INFO: Downloaded file to C:\\Users\\Asus\\stanza_resources\\resources.json\n",
      "2025-11-17 23:29:56 INFO: Loading these models for language: fr (French):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2025-11-17 23:29:56 INFO: Using device: cpu\n",
      "2025-11-17 23:29:56 INFO: Loading: tokenize\n",
      "2025-11-17 23:29:56 INFO: Loading: mwt\n",
      "2025-11-17 23:29:56 INFO: Loading: pos\n",
      "2025-11-17 23:29:58 INFO: Loading: lemma\n",
      "2025-11-17 23:29:58 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    direct jean castex et olivier v√©ran annoncer d...\n",
       "1    direct jean castex et olivier v√©ran annoncer d...\n",
       "2    on √™tre de accord pour le cons√©quence √©conomiq...\n",
       "3    renforcer le capacit√© de d√©pistage et le actio...\n",
       "4    on moi dire dans le oreillette que le patient ...\n",
       "Name: lemmatized_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizing in French Language\n",
    "\n",
    "\n",
    "nlp = stanza.Pipeline(lang='fr', processors='tokenize,mwt,pos,lemma')\n",
    "\n",
    "\n",
    "def extract_text(row):\n",
    "    if pd.notna(row.get(\"extended_tweet.full_text\")):\n",
    "        return row[\"extended_tweet.full_text\"]\n",
    "    elif pd.notna(row.get(\"quoted_status.extended_tweet.full_text\")):\n",
    "        return row[\"quoted_status.extended_tweet.full_text\"]\n",
    "    elif pd.notna(row.get(\"quoted_status.text\")):\n",
    "        return row[\"quoted_status.text\"]\n",
    "    else:\n",
    "        return row.get(\"text\", \"\")\n",
    "\n",
    "df[\"clean_text\"] = df.apply(extract_text, axis=1)\n",
    "\n",
    "\n",
    "def clean_french_tweet(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)               \n",
    "    text = re.sub(r\"@\\w+\", \" \", text)                  \n",
    "    text = re.sub(r\"#(\\w+)\", r\" \\1 \", text)            \n",
    "    text = re.sub(r\"[^\\w\\s√Ä-√ø]\", \" \", text)            \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()           \n",
    "    return text\n",
    "df[\"clean_text\"] = df['clean_text'].apply(clean_french_tweet)\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [word.lemma for sent in doc.sentences for word in sent.words if word.lemma is not None]\n",
    "    return \" \".join(lemmas)\n",
    "df['lemmatized_text'] = df['clean_text'].apply(lemmatize_text)\n",
    "df['lemmatized_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7aa8b0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154914, 50000)\n"
     ]
    }
   ],
   "source": [
    "french_stopwords = stopwords.words('french')\n",
    "Vectorize = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,\n",
    "    max_features=50000,\n",
    "    stop_words=french_stopwords\n",
    ")\n",
    "X = Vectorize.fit_transform(df['lemmatized_text'])\n",
    "print(X.shape)\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9f207ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Train size: 123931 | Val size: 30983\n"
     ]
    }
   ],
   "source": [
    "# Train-test splitting\n",
    "\n",
    "print(len(y) == X.shape[0])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify = y, random_state = 40\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \"| Val size:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6c60327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best C: 0.1\n",
      "\n",
      "Validation Accuracy: 0.6328631830358584\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65     16535\n",
      "           1       0.60      0.62      0.61     14448\n",
      "\n",
      "    accuracy                           0.63     30983\n",
      "   macro avg       0.63      0.63      0.63     30983\n",
      "weighted avg       0.63      0.63      0.63     30983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model design\n",
    "svm = LinearSVC(class_weight=\"balanced\", max_iter=5000)\n",
    "\n",
    "# Grid of C values (inverse of regularization strength)\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on train data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = grid.predict(X_val)\n",
    "\n",
    "print(\"Best C:\", grid.best_params_[\"C\"])\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f65ee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best Params: {'alpha': 0.0001, 'loss': 'hinge'}\n",
      "\n",
      "Validation Accuracy: 0.6268276151437885\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64     16535\n",
      "           1       0.60      0.62      0.61     14448\n",
      "\n",
      "    accuracy                           0.63     30983\n",
      "   macro avg       0.63      0.63      0.63     30983\n",
      "weighted avg       0.63      0.63      0.63     30983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define model\n",
    "model = SGDClassifier(class_weight='balanced', max_iter=1000)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'alpha': [1e-3, 1e-4, 1e-5]  # Note: SGDClassifier uses 'alpha' = 1/C\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit to training set\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = grid.predict(X_val)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ea21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAST TEXT Implementation without Lemmatized words( Cause Lemmatization reduced accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6bc331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loading word vectors into memory...\n",
      "üîÑ Converting tweets to vectors...\n",
      "‚úÖ Vector shape: (154914, 300)\n",
      "\n",
      "‚úÖ Validation Accuracy: 0.610076493560985\n",
      "\n",
      "üßæ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63     16535\n",
      "           1       0.58      0.60      0.59     14448\n",
      "\n",
      "    accuracy                           0.61     30983\n",
      "   macro avg       0.61      0.61      0.61     30983\n",
      "weighted avg       0.61      0.61      0.61     30983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "fasttext_url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz\"\n",
    "local_path = \"cc.fr.300.vec.gz\"\n",
    "vec_file = \"cc.fr.300.vec\"\n",
    "\n",
    "if not os.path.exists(vec_file):\n",
    "    print(\"‚è≥ Downloading FastText French vectors...\")\n",
    "    urllib.request.urlretrieve(fasttext_url, local_path)\n",
    "    print(\"‚úÖ Downloaded. Unzipping...\")\n",
    "    with gzip.open(local_path, 'rb') as f_in:\n",
    "        with open(vec_file, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    print(\"‚úÖ Unzipped.\")\n",
    "\n",
    "\n",
    "print(\"üîÅ Loading word vectors into memory...\")\n",
    "ft_model = KeyedVectors.load_word2vec_format(vec_file)\n",
    "\n",
    "\n",
    "def text_to_vector(text, model, dim=300):\n",
    "    tokens = simple_preprocess(text, deacc=True)  \n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(dim)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "print(\"üîÑ Converting tweets to vectors...\")\n",
    "X = np.vstack(df[\"clean_text\"].apply(lambda x: text_to_vector(x, ft_model)))\n",
    "y = df[\"label\"].values\n",
    "\n",
    "print(\"‚úÖ Vector shape:\", X.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearSVC(class_weight=\"balanced\", max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(\"\\n‚úÖ Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nüßæ Classification Report:\\n\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9972b2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_meta shape: (154914, 7)\n",
      "   followers_count  friends_count  statuses_count  favourites_count  \\\n",
      "0        1338833.0          747.0             333             14154   \n",
      "1        1338833.0          747.0            3028              8582   \n",
      "2          89020.0          579.0            4238              1229   \n",
      "3          89020.0          579.0            1152                19   \n",
      "4          89020.0          579.0            1252              1375   \n",
      "\n",
      "   listed_count  verified  followers_to_friends_ratio  \n",
      "0             5       1.0                 1789.883690  \n",
      "1             1       1.0                 1789.883690  \n",
      "2            27       0.0                  179.035714  \n",
      "3            92       0.0                  179.035714  \n",
      "4             1       0.0                  179.035714  \n",
      "\n",
      "Feature Scores (F-test):\n",
      "followers_count: 0.06\n",
      "friends_count: 27.95\n",
      "statuses_count: 13285.75\n",
      "favourites_count: 3395.44\n",
      "listed_count: 962.60\n",
      "verified: 31.19\n",
      "followers_to_friends_ratio: 4.03\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_metadata(df):\n",
    "    meta = pd.DataFrame()\n",
    "\n",
    "    # Grab metadata (or fallback from quoted_status)\n",
    "    meta[\"followers_count\"] = df.get(\"user.followers_count\", df[\"quoted_status.user.followers_count\"])\n",
    "    meta[\"friends_count\"] = df.get(\"user.friends_count\", df[\"quoted_status.user.friends_count\"])\n",
    "    meta[\"statuses_count\"] = df.get(\"user.statuses_count\", df[\"quoted_status.user.statuses_count\"])\n",
    "    meta[\"favourites_count\"] = df.get(\"user.favourites_count\", df[\"quoted_status.user.favourites_count\"])\n",
    "    meta[\"listed_count\"] = df.get(\"user.listed_count\", df[\"quoted_status.user.listed_count\"])\n",
    "    meta[\"verified\"] = df.get(\"user.verified\", df[\"quoted_status.user.verified\"]).astype(float)\n",
    "\n",
    "    # Followers-to-friends ratio (avoid div by 0)\n",
    "    meta[\"followers_to_friends_ratio\"] = meta[\"followers_count\"] / (meta[\"friends_count\"] + 1)\n",
    "\n",
    "\n",
    "    return meta\n",
    "X_meta = extract_metadata(df)\n",
    "X_meta = X_meta.fillna(X_meta.median())\n",
    "\n",
    "y = df[\"label\"]\n",
    "print(\"X_meta shape:\", X_meta.shape)\n",
    "print(X_meta.head())\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k='all')\n",
    "selector.fit(X_meta, y)\n",
    "\n",
    "print(\"\\nFeature Scores (F-test):\")\n",
    "for name, score in zip(X_meta.columns, selector.scores_):\n",
    "    print(f\"{name}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62193968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TF IDF vectorization with metadata for SVM\n",
    "\n",
    "X_meta_selected = X_meta[[\n",
    "    \"statuses_count\",\n",
    "    \"favourites_count\",\n",
    "    \"listed_count\",\n",
    "    \"verified\",\n",
    "    \"friends_count\",\n",
    "    \"followers_to_friends_ratio\"\n",
    "]]\n",
    "\n",
    "X = Vectorize.fit_transform(df['lemmatized_text'])\n",
    "scaler = StandardScaler()\n",
    "X_meta_scaled = scaler.fit_transform(X_meta_selected)\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "X_meta_sparse = csr_matrix(X_meta_scaled)\n",
    "X_combined = hstack([X, X_meta_sparse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4294f05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7388245166704321\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76     16535\n",
      "           1       0.73      0.69      0.71     14448\n",
      "\n",
      "    accuracy                           0.74     30983\n",
      "   macro avg       0.74      0.74      0.74     30983\n",
      "weighted avg       0.74      0.74      0.74     30983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_combined, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "model = LinearSVC(class_weight='balanced', max_iter=50000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a0edae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best C: 0.1\n",
      "\n",
      "Validation Accuracy: 0.7759416454184552\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.81     16535\n",
      "           1       0.85      0.63      0.72     14448\n",
      "\n",
      "    accuracy                           0.78     30983\n",
      "   macro avg       0.79      0.77      0.77     30983\n",
      "weighted avg       0.79      0.78      0.77     30983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model design\n",
    "svm = LinearSVC(class_weight=\"balanced\", max_iter=5000)\n",
    "\n",
    "# Grid of C values (inverse of regularization strength)\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on train data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = grid.predict(X_val)\n",
    "\n",
    "print(\"Best C:\", grid.best_params_[\"C\"])\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19e1dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best Params: {'alpha': 1e-05, 'loss': 'hinge'}\n",
      "\n",
      "Validation Accuracy: 0.7779427427944356\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.81     16535\n",
      "           1       0.86      0.63      0.72     14448\n",
      "\n",
      "    accuracy                           0.78     30983\n",
      "   macro avg       0.80      0.77      0.77     30983\n",
      "weighted avg       0.79      0.78      0.77     30983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = SGDClassifier(class_weight='balanced', max_iter=1000)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'alpha': [1e-3, 1e-4, 1e-5]  # Note: SGDClassifier uses 'alpha' = 1/C\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit to training set\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = grid.predict(X_val)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86f95c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText shape: (154914, 300)\n",
      "‚úÖ Final FastText + Metadata Accuracy: 0.7757802665978117\n",
      "üìä Final Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81     16535\n",
      "           1       0.85      0.63      0.72     14448\n",
      "\n",
      "    accuracy                           0.78     30983\n",
      "   macro avg       0.79      0.77      0.77     30983\n",
      "weighted avg       0.79      0.78      0.77     30983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def text_to_vector(text, model, dim=300):\n",
    "    tokens = simple_preprocess(text, deacc=True)  # tokenize & clean\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(dim)\n",
    "\n",
    "# Apply to all tweets\n",
    "X_fasttext = np.vstack(df[\"lemmatized_text\"].apply(lambda x: text_to_vector(x, ft_model)))\n",
    "print(\"FastText shape:\", X_fasttext.shape)\n",
    "\n",
    "\n",
    "# Scale metadata\n",
    "scaler = StandardScaler()\n",
    "X_meta_scaled = scaler.fit_transform(X_meta_selected)\n",
    "\n",
    "# Combine (both are dense)\n",
    "X_combined = np.hstack([X_fasttext, X_meta_scaled])\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_combined, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearSVC(class_weight=\"balanced\", max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(\"‚úÖ Final FastText + Metadata Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"üìä Final Classification Report:\\n\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84db342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (103380, 191)\n",
      "FastText vector shape: (103380, 300)\n",
      "‚úÖ Submission file saved as submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Best model so far: SDGClassifier Best Params: {'alpha': 1e-05, 'loss': 'hinge'}\n",
    "\n",
    "\n",
    "# Final Run:\n",
    "\n",
    "# ---------- Load Test Set ----------\n",
    "test_df = pd.read_json(\"../data/Kaggle2025/kaggle_test.jsonl\", lines=True)\n",
    "test_df = pd.json_normalize(test_df.to_dict(orient='records'))\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "# ---------- Reuse Cleaning Functions ----------\n",
    "def extract_text(row):\n",
    "    if pd.notna(row.get(\"extended_tweet.full_text\")):\n",
    "        return row[\"extended_tweet.full_text\"]\n",
    "    elif pd.notna(row.get(\"quoted_status.extended_tweet.full_text\")):\n",
    "        return row[\"quoted_status.extended_tweet.full_text\"]\n",
    "    elif pd.notna(row.get(\"quoted_status.text\")):\n",
    "        return row[\"quoted_status.text\"]\n",
    "    else:\n",
    "        return row.get(\"text\", \"\")\n",
    "\n",
    "def clean_french_tweet(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"@\\w+\", \" \", text)\n",
    "    text = re.sub(r\"#(\\w+)\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^\\w\\s√Ä-√ø]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# ---------- Clean Text ----------\n",
    "test_df[\"clean_text\"] = test_df.apply(extract_text, axis=1).apply(clean_french_tweet)\n",
    "\n",
    "# ---------- FastText Vectorization ----------\n",
    "def text_to_vector(text, model, dim=300):\n",
    "    tokens = simple_preprocess(text, deacc=True)\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(dim)\n",
    "\n",
    "X_fasttext_test = np.vstack(test_df[\"clean_text\"].apply(lambda x: text_to_vector(x, ft_model)))\n",
    "print(\"FastText vector shape:\", X_fasttext_test.shape)\n",
    "\n",
    "# ---------- Metadata Extraction ----------\n",
    "\n",
    "def extract_metadata(df):\n",
    "    meta = pd.DataFrame()\n",
    "    def get_first(row, keys): return next((row[k] for k in keys if k in row and pd.notna(row[k])), np.nan)\n",
    "\n",
    "    meta[\"followers_count\"] = df.get(\"user.followers_count\", df[\"quoted_status.user.followers_count\"])\n",
    "    meta[\"friends_count\"] = df.get(\"user.friends_count\", df[\"quoted_status.user.friends_count\"])\n",
    "    meta[\"statuses_count\"] = df.get(\"user.statuses_count\", df[\"quoted_status.user.statuses_count\"])\n",
    "    meta[\"favourites_count\"] = df.get(\"user.favourites_count\", df[\"quoted_status.user.favourites_count\"])\n",
    "    meta[\"listed_count\"] = df.get(\"user.listed_count\", df[\"quoted_status.user.listed_count\"])\n",
    "    meta[\"verified\"] = df.get(\"user.verified\", df[\"quoted_status.user.verified\"]).astype(float)\n",
    "    meta[\"followers_to_friends_ratio\"] = meta[\"followers_count\"] / (meta[\"friends_count\"] + 1)\n",
    "\n",
    "    meta = meta.fillna(meta.median())\n",
    "    return meta\n",
    "\n",
    "X_meta_test = extract_metadata(test_df)\n",
    "\n",
    "# ---------- Select Same Features as Training ----------\n",
    "X_meta_test_selected = X_meta_test[[\n",
    "    \"statuses_count\",\n",
    "    \"favourites_count\",\n",
    "    \"listed_count\",\n",
    "    \"verified\",\n",
    "    \"friends_count\",\n",
    "    \"followers_to_friends_ratio\"\n",
    "]]\n",
    "\n",
    "# ---------- Scale and Combine ----------\n",
    "X_meta_scaled_test = scaler.transform(X_meta_test_selected)\n",
    "X_test_combined = np.hstack([X_fasttext_test, X_meta_scaled_test])\n",
    "\n",
    "# ---------- Train Final Model on ALL Data ----------\n",
    "X_all = np.hstack([X_fasttext, scaler.transform(X_meta_selected)])\n",
    "model_final = LinearSVC(class_weight=\"balanced\", max_iter=5000)\n",
    "model_final.fit(X_all, y)\n",
    "\n",
    "# ---------- Predict and Export ----------\n",
    "y_kaggle_pred = model_final.predict(X_test_combined)\n",
    "\n",
    "kaggle_id = test_df['challenge_id']\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": kaggle_id.values,\n",
    "    \"Prediction\": y_kaggle_pred\n",
    "})\n",
    "\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"‚úÖ Submission file saved as submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ff844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d949aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
